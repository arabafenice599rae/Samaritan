
<p align="center">
  <img src="./logo.svg" alt="Samaritan Logo" width="260" />
</p>

<h1 align="center">Samaritan Lite</h1>

<p align="center">
  <em>A tiny, opinionated playground for the Samaritan 1.5 distributed brain.</em>
</p>

<p align="center">
  <a href="https://github.com/arabafenice599rae/Samaritan/actions/workflows/build.yml">
    <img src="https://github.com/arabafenice599rae/Samaritan/actions/workflows/build.yml/badge.svg" alt="Build Status">
  </a>
</p>

---

## âœ¨ What is Samaritan Lite?

Samaritan Lite is a **minimal, demonstrative implementation** of the Samaritan 1.5 architecture:

> A distributed, privacy-by-design brain where every installation is a full node,  
> not just a dumb client.

This repo is **not** a full FL / DP production stack.  
Itâ€™s a **small but realistic core** that shows:

- how a **neural engine** can be wrapped with
- a **safety policy core**, plus
- a tiny **meta-observer** that collects stats about the node.

Perfect for:

- experimenting locally,
- reviewing ideas for Samaritan 1.5,
- or using as a skeleton for a richer node later.

---

## ğŸ§± Repository layout

```text
Samaritan/
â”œâ”€ Cargo.toml              # Workspace: samaritan-core-lite + lite-node-demo
â”œâ”€ logo.svg                # Transparent brain logo
â”œâ”€ README.md               # You are here
â”‚
â”œâ”€ samaritan-core-lite/    # Core library (NeuralEngineLite + PolicyCore + MetaObserverLite)
â”‚  â”œâ”€ Cargo.toml
â”‚  â””â”€ src/
â”‚     â”œâ”€ lib.rs
â”‚     â”œâ”€ neural_engine_lite.rs
â”‚     â”œâ”€ policy_core.rs
â”‚     â””â”€ meta_observer.rs
â”‚
â””â”€ lite-node-demo/         # Small CLI node using the core library
   â”œâ”€ Cargo.toml
   â””â”€ src/
      â”œâ”€ main.rs
      â”œâ”€ simple_node.rs
      â”œâ”€ policy_core.rs        # wired into the demo
      â””â”€ meta_observer_lite.rs


â¸»

ğŸš€ Quick start

Requirements: recent Rust toolchain (rustup + stable).

Clone the repo:

git clone https://github.com/arabafenice599rae/Samaritan.git
cd Samaritan

Build everything:

cargo build

Run the CLI demo node:

cargo run -p lite-node-demo

Youâ€™ll see a prompt like:

=== Samaritan Lite Node Demo ===
Commands:
  - type a normal message to talk to the node
  - type "/stats" to see MetaObserverLite statistics
  - type "/reset_stats" to reset the statistics
  - type "/quit" to exit

Then:
	â€¢	type a normal message â†’ the node runs NeuralEngineLite + PolicyCore,
	â€¢	type /stats â†’ the node prints aggregated stats (turns, average length, etc.),
	â€¢	type /reset_stats â†’ counters are cleared,
	â€¢	type /quit â†’ exit.

â¸»

ğŸ§  Core concepts

1. NeuralEngineLite

A deterministic, rule-based â€œneural engineâ€ that simulates different response modes:
	â€¢	detects:
	â€¢	empty input,
	â€¢	long wall-of-text,
	â€¢	questions (?),
	â€¢	chooses a style:
	â€¢	Small talk / coaching,
	â€¢	Question answer,
	â€¢	Summary for long text,
	â€¢	always applies a hard maximum output length for safety.

It doesnâ€™t do real LLM inference.
Itâ€™s deliberately simple and testable, but structured like a real engine:
	â€¢	clear config struct (NeuralEngineLiteConfig),
	â€¢	pure, deterministic generate(...),
	â€¢	unit tests that verify:
	â€¢	mode selection,
	â€¢	length limits,
	â€¢	basic behavior.

â¸»

2. PolicyCore

A tiny safety / policy module that inspects:
	â€¢	user input, and
	â€¢	model output,

and returns a PolicyDecision:

enum PolicyDecisionKind {
    Allow,
    SafeRespond,
    Refuse,
}

Current hard-coded rules (for the demo):
	â€¢	detects self-harm phrases â†’ SafeRespond,
	â€¢	detects obvious crime / hacking keywords â†’ Refuse,
	â€¢	very rough check for possible credit-card-like numbers â†’ SafeRespond,
	â€¢	in strict_mode, can enforce stricter limits (e.g. very long outputs).

The idea: in the real Samaritan 1.5, PolicyCore becomes the Constitution.
Here you have a tiny, readable starting point.

â¸»

3. MetaObserverLite

A minimal observer wired inside the demo node that tracks things like:
	â€¢	number of turns,
	â€¢	how many times each PolicyDecisionKind was used,
	â€¢	average input / output length.

From the CLI you can:
	â€¢	/stats â†’ dump the current snapshot,
	â€¢	/reset_stats â†’ clear all counters.

Itâ€™s intentionally tiny, but keeps the same spirit as the full Meta-Observer:

observe the brain, donâ€™t just run it.

â¸»

ğŸ§ª Tests & CI

Run all tests locally:

cargo test

The repo ships with:
	â€¢	unit tests for:
	â€¢	NeuralEngineLite,
	â€¢	PolicyCore,
	â€¢	MetaObserverLite,
	â€¢	a GitHub Actions workflow (.github/workflows/build.yml) that:
	â€¢	builds the workspace,
	â€¢	runs the full test suite on every push / PR.

If the badge on top is green, the lite node and core library compile and all tests pass.

â¸»

ğŸ§­ Roadmap / Ideas

This repository is intentionally small, but it can grow in several directions:
	â€¢	add a simple YAML config for:
	â€¢	strict_mode,
	â€¢	max_output_chars,
	â€¢	maybe toggles for different policy profiles;
	â€¢	plug in a real LLM backend (local / remote) behind NeuralEngineLite;
	â€¢	expand PolicyCore into a proper policy engine:
	â€¢	more categories,
	â€¢	per-rule logging,
	â€¢	configuration and tests;
	â€¢	turn MetaObserverLite into a tiny metrics exporter (Prometheus / JSON over HTTP);
	â€¢	experiment with multi-node setups later, reusing the same API surface.

â¸»

ğŸ¤ Contributing

Right now this is a personal / experimental project.

If you want to play with it:
	1.	fork the repo,
	2.	make a small, focused change,
	3.	run:

cargo fmt
cargo clippy --all-targets --all-features
cargo test


	4.	open a Pull Request with a short description of what you changed and why.

â¸»

ğŸ“„ License

This repository is currently experimental.
See the LICENSE file (or future updates) for license details once stabilized.

